WARNING 07-08 07:46:15 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead, and make sure to uninstall `pynvml`. When both of them are installed, `pynvml` will take precedence and cause errors. See https://pypi.org/project/pynvml for more information.
Warning: Your installation of OpenCV appears to be broken: module 'cv2.dnn' has no attribute 'DictValue'.Please follow the instructions at https://github.com/opencv/opencv-python/issues/884 to correct your environment. The import of cv2 has been skipped.
2025-07-08 07:46:18,244	INFO worker.py:1694 -- Connecting to existing Ray cluster at address: 172.23.75.208:6379...
2025-07-08 07:46:18,253	INFO worker.py:1888 -- Connected to Ray cluster.
WARNING 07-08 07:46:22 arg_utils.py:1019] [DEPRECATED] Block manager v1 has been removed, and setting --use-v2-block-manager to True or False has no effect on vLLM behavior. Please remove --use-v2-block-manager in your engine argument. If your use case is not supported by SelfAttnBlockSpaceManager (i.e. block manager v2), please file an issue with detailed information.
WARNING 07-08 07:46:22 config.py:395] To see benefits of async output processing, enable CUDA graph. Since, enforce-eager is enabled, async output processor cannot be used
INFO 2025-07-08 07:46:22,870 arg_utils.py:128] entrypoints_args: EntrypointsArgs(host='172.23.75.208', port=30319, ssl_keyfile=None, ssl_certfile=None, server_log_level='info', launch_ray_cluster=False, ray_cluster_port=6379, disable_log_to_driver=False, request_output_queue_type='zmq', disable_log_requests_server=False, log_request_timestamps=True, config_file='configs/vllm.yml', disable_keep_serve_process_alive=False)
INFO 2025-07-08 07:46:22,871 arg_utils.py:129] manager_args: ManagerArgs(initial_instances=1, polling_interval=0.05, dispatch_policy='load', scaling_load_metric='remaining_steps', topk_random_dispatch=1, enable_migration=True, pair_migration_frequency=1, pair_migration_policy='defrag', migrate_out_threshold=-3.0, enable_scaling=False, min_instances=-1, max_instances=4, scaling_interval=10, scaling_policy='avg_load', scale_up_threshold=-10, scale_down_threshold=-60, log_instance_info=False, log_filename='server.log', enable_port_increment=True, enable_port_offset_store=False, enable_adaptive_pd=False, enable_pd_disagg=True, pd_ratio=[1, 1], load_registered_service=False, load_registered_service_path=None, enable_pdd_node_affinity_scheduling=False, is_group_kind_migration_backend=True, enable_engine_pd_disagg=False, enable_engine_semi_pd_disagg=None)
INFO 2025-07-08 07:46:22,872 arg_utils.py:130] instance_args: InstanceArgs(instance_type='no_constraints', simulator_mode=False, profiling_result_file_path=None, dispatch_load_metric='remaining_steps', dispatch_prefill_load_metric='kv_blocks_ratio', dispatch_prefill_as_decode_load_metric='adaptive_decode', dispatch_decode_load_metric='remaining_steps', dispatch_decode_as_prefill_load_metric='kv_blocks_ratio', enable_defrag=True, max_migration_concurrency=1, request_migration_policy='SR', migration_load_metric='remaining_steps', migration_backend='nccl', migration_buffer_blocks=32, migration_num_layers=1, migration_backend_init_timeout=10.0, kvtransfer_migration_backend_transfer_type='rdma', kvtransfer_migration_backend_naming_url='file:/tmp/llumnix/naming/', migration_last_stage_max_blocks=16, migration_max_stages=3, engine_disagg_inst_id_env_var=None, request_output_forwarding_mode='thread', enable_engine_pd_disagg=False, enable_engine_semi_pd_disagg=None, enable_migration=True, enable_adaptive_pd=False)
INFO 2025-07-08 07:46:22,873 arg_utils.py:131] engine_args: AsyncEngineArgs(model='/mnt/model/Qwen2.5-7B', served_model_name=None, tokenizer='/mnt/model/Qwen2.5-7B', skip_tokenizer_init=False, tokenizer_mode='auto', trust_remote_code=True, download_dir=None, load_format='auto', config_format=<ConfigFormat.AUTO: 'auto'>, dtype='auto', kv_cache_dtype='auto', quantization_param_path=None, seed=0, max_model_len=4096, worker_use_ray=True, distributed_executor_backend=None, pipeline_parallel_size=1, tensor_parallel_size=1, max_parallel_loading_workers=None, block_size=16, enable_prefix_caching=False, disable_sliding_window=False, use_v2_block_manager=False, swap_space=4, cpu_offload_gb=0, gpu_memory_utilization=0.9, max_num_batched_tokens=16000, max_num_seqs=512, max_logprobs=20, disable_log_stats=False, revision=None, code_revision=None, rope_scaling=None, rope_theta=None, tokenizer_revision=None, quantization=None, enforce_eager=True, max_context_len_to_capture=None, max_seq_len_to_capture=8192, disable_custom_all_reduce=False, tokenizer_pool_size=0, tokenizer_pool_type='ray', tokenizer_pool_extra_config=None, limit_mm_per_prompt=None, enable_lora=False, max_loras=1, max_lora_rank=16, enable_prompt_adapter=False, max_prompt_adapters=1, max_prompt_adapter_token=0, fully_sharded_loras=False, lora_extra_vocab_size=256, long_lora_scaling_factors=None, lora_dtype='auto', max_cpu_loras=None, device='auto', num_scheduler_steps=1, multi_step_stream_outputs=True, ray_workers_use_nsight=False, num_gpu_blocks_override=None, num_lookahead_slots=0, model_loader_extra_config=None, ignore_patterns=[], preemption_mode=None, scheduler_delay_factor=0.0, enable_chunked_prefill=False, guided_decoding_backend='outlines', speculative_model=None, speculative_model_quantization=None, speculative_draft_tensor_parallel_size=None, num_speculative_tokens=None, speculative_disable_mqa_scorer=False, speculative_max_model_len=None, speculative_disable_by_batch_size=None, ngram_prompt_lookup_max=None, ngram_prompt_lookup_min=None, spec_decoding_acceptance_method='rejection_sampler', typical_acceptance_sampler_posterior_threshold=None, typical_acceptance_sampler_posterior_alpha=None, qlora_adapter_name_or_path=None, disable_logprobs_during_spec_decoding=None, otlp_traces_endpoint=None, collect_detailed_traces=None, disable_async_output_proc=False, override_neuron_config=None, mm_processor_kwargs=None, scheduling_policy='fcfs', disable_log_requests=False)
INFO 2025-07-08 07:46:22,941 setup.py:129] Init Scaler on current node.
[36m(Scaler pid=69163)[0m WARNING 07-08 07:46:25 cuda.py:22] You are using a deprecated `pynvml` package. Please install `nvidia-ml-py` instead, and make sure to uninstall `pynvml`. When both of them are installed, `pynvml` will take precedence and cause errors. See https://pypi.org/project/pynvml for more information.
[36m(Scaler pid=69163)[0m Warning: Your installation of OpenCV appears to be broken: module 'cv2.dnn' has no attribute 'DictValue'.Please follow the instructions at https://github.com/opencv/opencv-python/issues/884 to correct your environment. The import of cv2 has been skipped.
[36m(Scaler pid=69163)[0m INFO 2025-07-08 07:46:27,294 scaler.py:117] Init Manager actor.
[36m(Scaler pid=69163)[0m Using blocking ray.get inside async actor. This blocks the event loop. Please use `await` on object ref with asyncio.gather if you want to yield execution to the event loop instead.
