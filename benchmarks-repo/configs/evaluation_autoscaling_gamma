PORT=1032
new_session_ratio=1.0
session_0_ratio=0.5
load_metric="consumed_speed"
migrate_strategy="LCFS"
priority_ratio=0.0

# Run real test

model=/mnt/data/models/huggingface-models/llama-trained/llama-7b/
num_prompts=10000

# oranges=("32" "128" "512" "1536")
# max_batch_total_tokens_vals=("8700" "7500" "8100" "8100")
# oranges=("1560")
oranges=("6144")
max_batch_total_tokens_vals=("12000")
instance_parallel_size=8
tensor_parallel_size=1

enable_load_control_prefill=1
dispatch_strategy=load
dispatch_mode=local
global_dispatch_strategy=BE
need_dispatch_frequency=1


need_migrate_frequency=4
migrate_out_threshold=3
migrate_in_threshold=3

scale_threshold=10
scale_strategy=avg_load
scale_up_threshold=$(echo "$scale_threshold" | bc -l)
scale_down_threshold=$(echo "$scale_threshold + 50" | bc -l)
min_replicas=1
max_replicas=16

imean=512
irange=6144
omean=512
# "uniform", "exponential", "capped_exponential"
odist=zipf
idist=zipf
qps=2
# "burst", "uniform", "poisson", "gamma"
query_distribution=gamma
coefficient_variation=$1
enable_migrate=$2
migrate_backend="gloo"
results_path="0415_scaling_gamma_gamma_512|6144_512|6144_16_cv{$1}"